	<section id="chap-kgs" class="chapter">
		<h2>Knowledge Graphs in Practice</h2>
		<p>In this chapter, we discuss some of the most prominent knowledge graphs that have emerged in the past years. We begin by discussing open knowledge graphs, most of which have been published on the Web per the guidelines and protocols described in Chapter&nbsp;<? echo ref("chap:publish"); ?>. We later discuss enterprise knowledge graphs that have been created by companies from diverse industries for a wide range of applications.</p>

		<section id="sec-openkgs" class="section">
		<h3>Open Knowledge Graphs</h3>
		<p>By <em>open knowledge graphs</em>, we refer to knowledge graphs published under the Open Data philosophy, namely that “<em>open means anyone can freely access, use, modify, and share for any purpose (subject, at most, to requirements that preserve provenance and openness)</em>”.<? echo footnote("See <a class=\"uri\" href=\"http://opendefinition.org/\">http://opendefinition.org/</a>"); ?> Many open knowledge graphs have been published in the form of <em>Linked Open Datasets</em>&nbsp;<? echo $references->cite("ldbook"); ?>, which are (RDF) graphs published under the Linked Data principles (see Section&nbsp;<? echo ref("sssec:ld"); ?>) following the Open Data philosophy. Many of the most prominent open knowledge graphs – including DBpedia&nbsp;<? echo $references->cite("LehmannIJJKMHMK15"); ?>, YAGO&nbsp;<? echo $references->cite("suchanek2007yago"); ?>, Freebase&nbsp;<? echo $references->cite("bollacker2007freebase"); ?>, and Wikidata&nbsp;<? echo $references->cite("VrandecicK14"); ?> – cover multiple domains, representing a broad diversity of entities and relationships; we first discuss these in turn. Later we discuss some of the other (specific) domains for which open knowledge graphs are currently available. Most of the open knowledge graphs we discuss in this section are modelled in RDF, published following Linked Data principles, and offer access to their data through dumps (RDF), node lookups (Linked Data), graph patterns (SPARQL) and, in some cases, edge patterns (Triple Pattern Fragments).</p>

		<h4 id="sssec-dbpedia" class="subsection">DBpedia</h4>
		<p>The DBpedia project was developed to extract a graph-structured representation of the semi-structured data embedded in Wikipedia articles&nbsp;<? echo $references->cite("auer2007dbpedia"); ?>, enabling the integration, processing, and querying of these data in a unified manner. The resulting knowledge graph is further enriched by linking to external open resources, including images, webpages, and external datasets such as DailyMed, DrugBank, GeoNames, MusicBrainz, New York Times, and WordNet&nbsp;<? echo $references->cite("LehmannIJJKMHMK15"); ?>. The DBpedia extraction framework consists of several components, corresponding to abstractions of Wikipedia article sources, graph storage and serialisation destinations, wiki-markup extractors, parsers, and extraction managers&nbsp;<? echo $references->cite("bizer2009dbpedia"); ?>. Specific extractors are designed to process labels, abstracts, interlanguage links, images, redirects, disambiguation pages, external links, internal pagelinks, homepages, categories, and geocoordinates. The content in the DBpedia knowledge graph is not only multidomain, but also multilingual: as of 2012, DBpedia contained labels and abstracts in up to 97 different languages&nbsp;<? echo $references->cite("mendes2012dbpedia"); ?>. Entities within DBpedia are classified using four different schemata in order to address varying requirements&nbsp;<? echo $references->cite("bizer2009dbpedia"); ?>. These schemata include a Simple Knowledge Organization System (SKOS) representation of Wikipedia categories, a Yet Another Great Ontology (YAGO) classification schema (discussed presently), an Upper Mapping and Binding Exchange Layer (UMBEL) ontology categorisation schema, and a custom schema called the DBpedia ontology with classes such as <code>Person</code>, <code>Place</code>, <code>Organisation</code>, and <code>Work</code>&nbsp;<? echo $references->cite("LehmannIJJKMHMK15"); ?>. DBpedia also supports live synchronisation in order to remain consistent with dynamic Wikipedia articles&nbsp;<? echo $references->cite("LehmannIJJKMHMK15"); ?>.</p>

		<h4 id="sssec-yago" class="subsection">Yet Another Great Ontology</h4>
		<p>YAGO likewise extracts graph-structured data from Wikipedia, which are then unified with the hierarchical structure of WordNet to create a “<em>light-weight and extensible ontology with high quality and coverage</em>”&nbsp;<? echo $references->cite("suchanek2007yago"); ?>. This knowledge graph aims to be applied for various information technology tasks, such as machine translation, word sense disambiguation, query expansion, document classification, data cleaning, information integration, etc. While earlier approaches automatically extracted structured knowledge from text using pattern matching, natural language processing (NLP), and statistical learning, the resulting content tended to lack in quality when compared with what was possible through manual construction&nbsp;<? echo $references->cite("suchanek2007yago"); ?>. However, manual construction is costly, making it challenging to achieve broad coverage and keep the data up-to-date. In order to extract data with high coverage and quality, YAGO (like DBpedia) mostly extracts data from Wikipedia infoboxes and category pages, which contain core entity information and lists of articles for a specific category, respectively. These, in turn, are unified with hierarchical concepts from WordNet&nbsp;<? echo $references->cite("suchanek2008yago"); ?>. A schema – called the YAGO model – provides a vocabulary defined in RDFS; this model allows for representing words as entities, capturing synonymy and ambiguity&nbsp;<? echo $references->cite("suchanek2007yago"); ?>. The model further supports reification, \(n\)-ary relations, and data types&nbsp;<? echo $references->cite("suchanek2008yago"); ?>. Refinement mechanisms employed within YAGO include canonicalisation, where each edge and node is mapped to a unique identifier and duplicate elements are removed, and type checking, where nodes that cannot be assigned to a class by deductive or inductive methods are eliminated&nbsp;<? echo $references->cite("suchanek2008yago"); ?>. YAGO would be extended in later years to support spatio-temporal context&nbsp;<? echo $references->cite("YAGO"); ?> and multilingual Wikipedias&nbsp;<? echo $references->cite("MahdisoltaniBS15"); ?>.</p>

		<h4 id="sssec-freebase" class="subsection">Freebase</h4>
		<p>Freebase was a general-purpose, broad collection of human knowledge that aimed to address some of the large-scale information integration problems associated with the decentralised nature of the Semantic Web, such as uneven adoption, implementation challenges, and distributed query performance limitations&nbsp;<? echo $references->cite("bollacker2007platform"); ?>. Unlike DBpedia and YAGO – which are mostly extracted from Wikipedia/WordNet – Freebase solicited contributions directly from human editors. Included in the Freebase platform were a scalable data store with versioning mechanisms; a large data object store (LOB) for the storage of text, image, and media files; an API that could be queried using the Metaweb Query Language (MQL); a Web user interface; and a lightweight typing system&nbsp;<? echo $references->cite("bollacker2007platform"); ?>. The latter typing system was designed to support collaborative processes. Rather than forcing ontological correctness or logical consistency, the system was implemented as a loose collection of structuring mechanisms – based on datatypes, semantic classes, properties, schema definitions, etc. – that allowed for incompatible types and properties to coexist simultaneously&nbsp;<? echo $references->cite("bollacker2007platform"); ?>. Content could be added to Freebase interactively through the Web user interface or in an automated way by leveraging the API’s write functionality. Freebase had been acquired by Google in 2010, where the content of Freebase formed an important part of the Google Knowledge Graph announced in 2012&nbsp;<? echo $references->cite("GoogleKG"); ?>. When Freebase became read-only as of March 2015, the knowledge graph contained over three billion edges. Much of this content was subsequently migrated to Wikidata&nbsp;<? echo $references->cite("pellissier2016freebase"); ?>.</p>

		<h4 id="sssec-wikidata" class="subsection">Wikidata</h4>
		<p>Wikipedia contains a wealth of semi-structured data embedded in info-boxes, lists, tables, etc., as exploited by DBpedia and YAGO. However, these data have traditionally been curated and updated manually across different articles and languages; for example, a goal scored by a Chilean football player may require manual updates in the player's article, the tournament article, the team article, lists of top scorers, and so forth, across hundreds of language versions. Manual curation has led to a variety of data quality issues, including contradictory data in different articles, languages, etc. The Wikimedia Foundation uses Wikidata as a centralised, collaboratively-edited knowledge graph to supply Wikipedia – and arbitrary other clients – with data. Under this vision, a fact could be added to Wikidata once, triggering the automatic update of potentially multitudinous articles in Wikipedia across different languages&nbsp;<? echo $references->cite("VrandecicK14"); ?>. Like Wikipedia, Wikidata is also considered a secondary source containing <em>claims</em> that should reference primary sources, though claims can also be initially added without reference&nbsp;<? echo $references->cite("PiscopoKPS17"); ?>. Wikidata further allows for different viewpoints in terms of potentially contradictory (referenced) claims&nbsp;<? echo $references->cite("VrandecicK14"); ?>. Wikidata is multilingual, where nodes and edges are assigned language-agnostic <code>Qxx</code> and <code>Pxx</code> codes (see Figure&nbsp;<? echo ref("fig:ld"); ?>) and are subsequently associated with labels, aliases, and descriptions in various languages&nbsp;<? echo $references->cite("KaffeePVSCP17"); ?>, allowing claims to be surfaced in these languages. Collaborative editing is not only permitted on the data level, but also on the schema level, allowing users to add or modify lightweight semantic axioms&nbsp;<? echo $references->cite("PiscopoS18"); ?> – including sub-classes, sub-properties, inverse properties, etc. – as well as shapes&nbsp;<? echo $references->cite("BonevaDFG19"); ?>. Wikidata offers various access protocols&nbsp;<? echo $references->cite("malyshev2018getting"); ?> and has received broad adoption, being used by Wikipedia to generate infoboxes in certain domains&nbsp;<? echo $references->cite("SaezH18"); ?>, being supported by Google&nbsp;<? echo $references->cite("pellissier2016freebase"); ?>, and having been used as a data source for prominent end-user applications such as Apple’s Siri, amongst others&nbsp;<? echo $references->cite("malyshev2018getting"); ?>.</p>

		<h4 id="sssec-other-open-kgs" class="subsection">Other open cross-domain knowledge graphs</h4>
		<p>Aside from DBpedia, YAGO, Freebase and Wikidata, a number of other cross-domain knowledge graphs have been developed down through the years. BabelNet&nbsp;<? echo $references->cite("NavigliPonzetto:12"); ?>, like YAGO, is based on unifying WordNet and Wikipedia, but with the integration of additional knowledge graphs such as Wikidata, and a focus on creating a knowledge graph of multilingual lexical forms (organised into multilingual synsets) by transforming lexicographic resources such as Wiktionary and OmegaWiki into knowledge graphs. Compared to other knowledge graphs, lexicalised knowledge graphs such as BabelNet bring together the encyclopedic information found in Wikipedia with the lexicographic information usually found in monolingual and bilingual dictionaries. The Cyc project&nbsp;<? echo $references->cite("lenat1995cyc"); ?> aims to encode common-sense knowledge in a machine-readable way, where over 900 person-years of effort&nbsp;<? echo $references->cite("MatuszekCWD06"); ?> have, since 1986, gone into the creation of 2.2 million facts and rules. Though Cyc is proprietary, an open subset called OpenCyc has been published, where we refer to the comparison by <? echo $references->citet("FarberBMR18"); ?> of DBpedia, Freebase, OpenCyc, and YAGO for further details. The Never Ending Language Learning (NELL) project&nbsp;<? echo $references->cite("MitchellCHTYBCM18"); ?> has, since 2010, extracted a graph of 120 million edges from the text of web pages using OIE methods (see Chapter&nbsp;<? echo ref("chap:create"); ?>). Each such open knowledge graph applies different combinations of the languages and techniques discussed in this book over different sources with differing results.</p>

		<h4 id="sssec-domain-specific-open-kgs" class="subsection">Domain-specific open knowledge graphs</h4>
		<p>Open knowledge graphs have been published in a variety of specific domains. <? echo $references->citet("SchmachtenbergBP14"); ?> identify the most prominent domains in the context of Linked Data as follows: <em>media</em>, relating to news, television, radio, etc. (e.g., the BBC World Service Archive&nbsp;<? echo $references->cite("RaimondFSA14"); ?>); <em>government</em>, relating to the publication of data for transparency and development (e.g., by the U.S.&nbsp;<? echo $references->cite("HendlerHMT12"); ?> and U.K.&nbsp;<? echo $references->cite("ShadboltO13"); ?> governments); <em>publications</em>, relating to academic literature in various disciplines (e.g., OpenCitations&nbsp;<? echo $references->cite("PeroniSV17"); ?>, SciGraph&nbsp;<? echo $references->cite("IanaJNBHP19"); ?>, Microsoft Academic Knowledge Graph&nbsp;<? echo $references->cite("MAKG"); ?>); <em>geographic</em>, relating to places and regions of interest (e.g., LinkedGeoData&nbsp;<? echo $references->cite("StadlerLHA12"); ?>); <em>life sciences</em>, relating to proteins, genes, drugs, diseases, etc. (e.g., Bio2RDF&nbsp;<? echo $references->cite("CallahanCAD13"); ?>); and <em>user-generated content</em>, relating to reviews, open source projects, etc. (e.g., Revyu&nbsp;<? echo $references->cite("HeathM08a"); ?>). Open knowledge graphs have also been published in other domains, including <em>cultural heritage</em>&nbsp;<? echo $references->cite("HyvonenMKAKRSTPKVTPFSPLN09"); ?>, <em>music</em>&nbsp;<? echo $references->cite("RaimondSS09"); ?>, <em>law</em>&nbsp;<? echo $references->cite("Montiel-Ponsoda17"); ?>, <em>theology</em>&nbsp;<? echo $references->cite("SherifN15"); ?>, and even <em>tourism</em>&nbsp;<? echo $references->cite("LuLS16,abs-1805-05744,MaturanaALMH18,ZhangCHYAL19"); ?>. The envisaged applications for such knowledge graphs are as varied as the domains from which they emanate, but often relate to integration&nbsp;<? echo $references->cite("RaimondSS09,CallahanCAD13"); ?>, recommendation&nbsp;<? echo $references->cite("RaimondSS09,LuLS16"); ?>, transparency&nbsp;<? echo $references->cite("HendlerHMT12,ShadboltO13"); ?>, archiving&nbsp;<? echo $references->cite("HyvonenMKAKRSTPKVTPFSPLN09,RaimondFSA14"); ?>, decentralisation&nbsp;<? echo $references->cite("HeathM08a"); ?>, multilingual support&nbsp;<? echo $references->cite("SherifN15"); ?>, regulatory compliance&nbsp;<? echo $references->cite("Montiel-Ponsoda17"); ?>, etc.</p>
		</section>

		<section id="ssec-enterprise-kgs" class="section">
		<h3>Enterprise Knowledge Graphs</h3>
		<p>A variety of companies have announced the creation of proprietary “enterprise knowledge graphs” with a variety of goals in mind, which include: improving search capabilities&nbsp;<? echo $references->cite("GoogleKG,BingKG,AmazonKG,AirBnBKG,UberKG"); ?>, providing user recommendations&nbsp;<? echo $references->cite("AirBnBKG,UberKG"); ?>, implementing conversational/personal agents&nbsp;<? echo $references->cite("eBayKG"); ?>, enhancing targeted advertising&nbsp;<? echo $references->cite("LinkedInKG"); ?>, empowering business analytics&nbsp;<? echo $references->cite("LinkedInKG"); ?>, connecting users&nbsp;<? echo $references->cite("LinkedInKG,NoyGJNPT19"); ?>, extending multilingual support&nbsp;<? echo $references->cite("LinkedInKG"); ?>, facilitating research and discovery&nbsp;<? echo $references->cite("AstraZenecaKG"); ?>, assessing and mitigating risk&nbsp;<? echo $references->cite("ThompsonReutersKG,MaanaKG"); ?>, tracking news events&nbsp;<? echo $references->cite("BloombergKG"); ?>, and increasing transport automation&nbsp;<? echo $references->cite("HensonSTK19"); ?>, amongst (many) others. Though highly diverse, these enterprise knowledge graphs do follow some high-level trends, as reflected in the discussion by <? echo $references->citet("NoyGJNPT19"); ?>: (1) data are typically integrated into the knowledge graph from a variety of both external and internal sources (often involving text); (2) the enterprise knowledge graph is often very large, with millions or even billions of nodes and edges, posing challenges in terms of scalability; (3) refinement of the initial knowledge graph – adding new links, consolidating duplicate entities, etc. – is important to improve quality; (4) techniques to keep the knowledge graph up-to-date with the domain are often crucial; (5) a mix of ontological and machine learning representations are often combined or used in different situations in order to draw conclusions from the enterprise knowledge graph; (6) the ontologies used tend to be lightweight, often simple taxonomies representing a hierarchy of classes or concepts. We now discuss the main industries in which enterprise knowledge graphs have been deployed.</p>

		<h4 id="sssec-web-search" class="subsection">Web search</h4>
		<p>Web search engines have traditionally focused on matching a query string with sub-strings in web documents. The Google Knowledge Graph&nbsp;<? echo $references->cite("GoogleKG,NoyGJNPT19"); ?> rather promoted a paradigm of “<em>things not strings</em>” – analogous to semantic search&nbsp;<? echo $references->cite("GuhaMM03"); ?> – where the search engine would now try to identify the entities that a particular search may be expressing interest in. The knowledge graph itself describes these entities and how they interrelate. One of the main user-facing applications of the Google Knowledge Graph is the “Knowledge Panel”, which presents a pane on the right-hand side of (some) search results describing the principal entity that the search appears to be seeking, including some images, attribute–value pairs, and a list of related entities that users also search for. The Google Knowledge Graph was key to popularising the modern usage of the phrase “knowledge graph” (see Appendix&nbsp;<? echo ref("chap:defs"); ?>). Other major search engines, such as Microsoft Bing<? echo footnote("Microsoft’s Knowledge Graph was previously called “Satori” (meaning <em>understanding</em> in Japanese)."); ?>&nbsp;<? echo $references->cite("BingKG"); ?>, would later announce knowledge graphs along similar lines.</p>

		<h4 id="sssec-commerce" class="subsection">Commerce</h4>
		<p>Enterprise knowledge graphs have also been announced by companies that are principally concerned with selling or renting goods and services. A prominent example of such a knowledge graph is that used by Amazon&nbsp;<? echo $references->cite("AmazonKG,dong2019building"); ?>, which describes the products on sale in their online marketplace. One of the main stated goals of this knowledge graph is to enable more advanced (semantic) search features for products, as well as to improve product recommendations to users of its online marketplace. Another knowledge graph for commerce was announced by eBay&nbsp;<? echo $references->cite("eBayKG"); ?>, which encodes product descriptions and shopping behaviour patterns, and is used to power conversational agents that help users to find relevant products through a natural language interface. Airbnb&nbsp;<? echo $references->cite("AirBnBKG"); ?> has also described a knowledge graph that encodes accommodation for rent, places, events, experiences, neighbourhoods, users, tags, etc., on top of which a taxonomic schema is defined. This knowledge graph is used to offer potential clients recommendations of attractions, events, and activities available in the neighbourhood of a particular home for rent. Uber&nbsp;<? echo $references->cite("UberKG"); ?> has similarly announced a knowledge graph focused on food and restaurants for their “Uber Eats” delivery service. The goals are again to offer semantic search features and recommendations to users who are uncertain of precisely what kind of food they are looking for.</p>

		<h4 id="sssec-social-networks" class="subsection">Social networks</h4>
		<p>Enterprise knowledge graphs have also emerged in the context of social networking services. Facebook&nbsp;<? echo $references->cite("NoyGJNPT19"); ?> has gathered together a knowledge graph describing not only social data about users, but also the entities they are interested in, including celebrities, places, movies, music, etc., in order to connect people, understand their interests, and provide recommendations. LinkedIn&nbsp;<? echo $references->cite("LinkedInKG"); ?> announced a knowledge graph containing users, jobs, skills, companies, places, schools, etc., on top of which a taxonomic schema is defined. The knowledge graph is used to provide multilingual translations of important concepts, to improve targeted advertising, to provide advanced features for job search and people search, and likewise to provide recommendations matching jobs to people (and vice versa). Another knowledge graph has been created by Pinterest&nbsp;<? echo $references->cite("PinterestKG"); ?>, describing users and their interests, the latter being organised into a taxonomy. The main use-cases for the knowledge graph are to help users to more easily find content of interest to them, as well as to enhance revenue through targeted advertisements.</p>

		<h4 id="sssec-finance" class="subsection">Finance</h4>
		<p>The financial sector has also seen deployment of enterprise knowledge graphs. Amongst these, Bloomberg&nbsp;<? echo $references->cite("BloombergKG"); ?> has proposed a knowledge graph that powers financial data analytics, including sentiment analysis for companies based on current news reports and tweets, a question answering service, as well as detecting emerging events that may affect stock values. Thomson Reuters (Refinitiv)&nbsp;<? echo $references->cite("ThompsonReutersKG"); ?> has likewise announced a knowledge graph encoding “the financial ecosystem” of people, organisations, equity instruments, industry classifications, joint ventures and alliances, supply chains, etc., using a taxonomic schema to organise these entities. Some of the applications they mention for the knowledge graph include supply chain monitoring, risk assessment, and investment research. Knowledge graphs have also been used for deductive reasoning, with Banca d’Italia&nbsp;<? echo $references->cite("BellomariniFGS19"); ?> using rule-based reasoning to determine, for example, the percentage of ownership of a company by various stakeholders. Other companies exploring financial knowledge graphs include Accenture&nbsp;<? echo $references->cite("AccentureKG"); ?>, Capital One&nbsp;<? echo $references->cite("CapitalOneKG"); ?>, Wells Fargo&nbsp;<? echo $references->cite("WellsFargoKG"); ?>, amongst various others.</p>

		<h4 id="sssec-other-industries" class="subsection">Other industries</h4>
		<p>Enterprises have also been actively developing knowledge graphs to enable novel applications in a variety of other industries, including: <em>healthcare</em>, where IBM are exploring use-cases for drug discovery&nbsp;<? echo $references->cite("NoyGJNPT19"); ?> and information extraction from package inserts&nbsp;<? echo $references->cite("GentileGRW19"); ?>, while AstraZeneca&nbsp;<? echo $references->cite("AstraZenecaKG"); ?> are using a knowledge graph to advance genomics research and disease understanding; <em>transport</em>, where Bosch are exploring a knowledge graph of scenes and locations for driving automation&nbsp;<? echo $references->cite("HensonSTK19"); ?>; <em>oil &amp; gas</em>, where Maana&nbsp;<? echo $references->cite("MaanaKG"); ?> are using knowledge graphs to perform data integration for risk mitigation regarding oil wells and drilling; and more besides.</p>
		</section>
	</section>
